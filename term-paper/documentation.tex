% !TEX encoding = UTF-8 Unicode
% !!!  THIS FILE IS UTF-8 !!!
% !!!  MAKE SURE YOUR LaTeX Editor IS CONFIGURED TO USE UTF-8 !!!

% Computational and Data Science Course Paper LaTeX Template
% University of Applied Sciences of the Grisons
% ---------------------------------------------------------------
% Author: Corsin Capol corsin.capol@fhgr.ch
% ---------------------------------------------------------------

%-------------------------
% header
% ------------------------
\documentclass[a4paper,12pt]{scrartcl}
\linespread {1.25}

%-------------------------
% packages and config
% ------------------------
\input{packages_and_configuration}


%-------------------------
% document begin
%-------------------------
\begin{document}

%-------------------------
% title
%-------------------------
\input{title}
\clearpage
\pagestyle{plain} % Setzt den Seitenstil auf normale Seitenzahlen
\setcounter{page}{1} % Setzt den Seitenzähler auf 1


\twocolumn

\section{Einleitung}

Die Präsenz von Online-Zeitschriften wird stetig grösser. 
Gemäss dem Medienbarometer der Schweiz haben die Online-Zeitschriften im Jahr 2023 eine Meinungsmacht von 27\% \cite{bakomMediengattungen2023}.
Im Vergleich zu den Printmedien gibt es für die digitalen Newsportale die Möglichkeit, Artikel nach der Veröffentlichung noch zu ändern.
Wie häufig Schweizer Online-Zeitschriften davon Gebrauch machen, wird in dieser Arbeit untersucht.
Um dies herauszufinden, wurden Medienartikel der ausgewählten Zeitschriften in einem regelmässigen Zeitabstand heruntergeladen und in eine Datenbank gespeichert.


\subsection{Eingrenzung}
Die Auswahl der zu untersuchenden Online-Zeitschriften basiert auf deren unterschiedlichen Platzierungen im Medienqualitätsrating (MQR)~\cite{MedienqualitaetsratingMQR24Verein2024}.
Folgende Medien wurden ausgewählt: \textit{20 Minuten}, \textit{Watson} und \textit{SRF News}.

\section{Methodik}

Zur Beantwortung der Forschungsfrage wurden mehrere Python-Applikationen entwickelt. 
Der zugehörige Quellcode ist in einem öffentlichen GitHub-Repository\footnote{\url{https://github.com/dariohollbach/swiss-news-change-tracker}} zugänglich.

\begin{figure}[t]
    \centering
    \includegraphics[width=0.5\textwidth]{architecture.drawio.png}
    \caption{Architektur}
    \label{fig:architecture}
\end{figure}

\subsection{Web Scraping}

Der Prozess der Datenextraktion von Webseiten wird als Web-Scraping bezeichnet und gewinnt zunehmend an Bedeutung, da immer mehr Informationen online verfügbar sind~\cite[S. V]{penmanWebScrapingPython2015}.
Die ausgewählten Medien verfügen alle über einen RSS-Feed.
Um diesen auszulesen, wurde das Python Modul \texttt{feedparser} verwendet.
Von dem RSS Feed können die Links zu den Artikeln herausgelesen werden.
Mit dem Python Modul \texttt{requests} wurde der Inhalt der Artikel heruntergeladen.
Da die Artikel aus dem Web stammen, ist das Format HTML\@. 
Für die Datenbank ist nur der Text eines Artikels von Relevanz.
Dieser Text-Inhalt wurde mithilfe vom Python Modul \texttt{BeautifulSoup} extrahiert.
Beautiful Soup ist ein beliebtes Modul, das eine Webseite parst und eine Schnittstelle zur Navigation im Inhalt bereitstellt~\cite[S. 26]{penmanWebScrapingPython2015}.

In Python wurde ein Interface für die Crawler der verschiedenen Medien definiert.
Jeder Crawler implementiert dieses Interface und ist für das Herunterladen und Parsen der Artikel eines Mediums verantwortlich.
Der Hauptteil der Applikation ruft die verschiedenen Crawler auf. 
Dies ist in Abbildung \ref{fig:architecture} dargestellt.

Um die Applikation in einem regelmässigem Intervall auszuführen, wurde auf dem Raspberry Pi ein Cron Job erstellt. 
Beim Erstellen des Cron Jobs sind Probleme aufgetreten, welche schwierig nachzuvollziehen waren. 
Deshalb wurde die Ausgabe der Python Applikation in ein Log-File \texttt{swiss\_news\_change\_tracker\_log} gespeichert.

\subsection{Datenbank}

Für die Speicherung der heruntergeladenen Artikel und deren Änderungen wurde eine SQLite-Datenbank verwendet.
SQLite wurde gewählt, da es eine einfache und leichtgewichtige Lösung ist, welche keine zusätzliche Server-Infrastruktur benötigt.
Dies ist besonders vorteilhaft, da die Applikation auf einem Raspberry-Pi ausgeführt wird.
Die Datenbank besteht aus drei Tabellen: Eine Tabelle für die Zeitschrifen, eine für die Artikel und eine für die Änderungen.
Das zugehörige Entity-Relationship-Diagramm (ER-Diagramm) der Datenbank ist in Abbildung \ref{fig:database_er_diagram} im Anhang dargestellt.
Wie in Abbildung \ref{fig:architecture} ersichtlich, erfolgt der Zugriff auf die Datenbank durch den Database-Manager mittels SQL-Abfragen.

\subsection{Visualisierung der Änderungen}

Da die reinen Daten der Artikeländerungen mittels SQL-Abfragen nur schwer zu interpretieren sind, wurde eine Web-Applikation zur Visualisierung entwickelt.
Das Frontend wurde mit dem JavaScript-Framework \texttt{Vue.js} umgesetzt.
Für den Datenzugriff wurde ein Flask Server entwickelt, welcher dem Frontend die in der Datenbank gespeicherten Artikel und deren Änderungen zur Verfügung stellt.
Diese API greift auf dieselbe Datenbankinfrastruktur zu wie der Web-Scraper (Siehe Abbildung \ref{fig:architecture}).
Die Web-Applikation stellt die Artikel der verschiedenen Medien übersichtlich dar. 
Vorhandene Änderungen eines Artikels können durch Anklicken eines Artikels aufgeklappt werden, was eine visuelle Analyse der Modifikationen ermöglicht.

\subsubsection{Klassifikation der Änderungen}
Eine erste Analyse der Daten zeigte, dass viele Änderungen lediglich Korrekturen von Rechtschreib- oder Tippfehlern umfassen. 
Um solche geringfügige Anpassungen von inhaltlichen Modifikationen zu unterscheiden, wurde eine Klassifizierung der Änderungen vorgenommen.
Aufgrund der überschaubaren Anzahl an Änderungen, wurde dieser Prozess manuell durchgeführt.
Dazu wurde die Web-Anwendung um ein Dropdown-Menü erweitert, über welches jede Änderung als Tippfehler oder inhaltliche Anpassung klassifiziert werden kann.

\subsection{Analyse der Daten}
Für die Auswertung der klassifizierten Daten wurde ein Python-Skript mit der Bibliothek \texttt{Pandas} und \texttt{matplotlib} entwickelt. 
Die resultierende Analyse ermöglicht die Beantwortung der Forschungsfrage.
Die Relevanz solcher Werkzeuge wird in der Fachliteratur betont: \enquote{Im heutigen datengesteuerten Zeitalter stehen Organisationen [...] vor der Herausforderung, aus den riesigen Datenmengen [...] aussagekräftige Informationen zu gewinnen. [...]. Genau hier kommt Pandas ins Spiel.}~\cite[S. 1]{firdoseUltimatePandasData2024}.


\section{Resultate}

In der Zeit vom 10. November 2025 bis zum 20. November 2025 wurden insgesammt 1767 Artikel von den drei ausgewählten Medien heruntergeladen.
Davon wurden 381 Artikel mindestens einmal geändert.

\begin{table*}[b]
    \centering
    \caption{Zusammenfassung der Artikel und Änderungen pro Medium}
    \label{tab:change_summary}
    \begin{tabular}{lrrrr}
        \hline
        \textbf{Zeitung} & \textbf{Total Artikel} & \textbf{Total Änderungen} & \textbf{Tippfehler} & \textbf{Inhaltliche Änd.} \\
        \hline
        20 Minuten & 624 & 148 & 88 & 60 \\
        Watson & 601 & 96 & 51 & 45 \\
        SRF News & 542 & 137 & 78 & 59 \\
        \hline
        \textbf{Total} & \textbf{1767} & \textbf{381} & \textbf{217} & \textbf{164} \\
        \hline
    \end{tabular}
\end{table*}

Die Tabelle \ref{tab:change_summary} fasst alle gesammelten Daten zusammen. 
Obwohl die manuelle Klassifikation eine gewisse Ungenauigkeit durch subjektive Einschätzungen mit sich bringt, bietet sie dennoch einen Überblick über die Art der vorgenommenen Änderungen.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.5\textwidth]{article_and_change_counts_by_newspaper.png}
    \caption{Anzahl \"{A}nderungen pro Medium}
    \label{fig:article_and_change_counts_by_newspaper}
\end{figure}
Abbildung \ref{fig:article_and_change_counts_by_newspaper} zeigt die Anzahl Änderungen pro Medium.
Es ist ersichlich, dass im Durchschnitt ungefähr jeder fünfte Artikel geändert wurde.
\textit{20 Minuten} und \textit{SRF News} weisen dabei ähnlich viele Änderungen auf, während \textit{Watson} etwas weniger Anpassungen vornimmt.
Bei der Interpretation ist zu beachten, dass bei vielen Artikeln auch nur die Strukturierung von Texten geändert wurde, ohne dass der eigentliche Inhalt angepasst wurde.
Dies wurde ebenfalls als Tippfehler klassifiziert.

Zum Resultat der Arbeit gehört auch die Web-Applikation zur Visualisierung der Artikeländerungen.
Denn die Analyse der reinen Zahlen gibt keinen Einblick in die inhaltlichen Änderungen.
Die Abbildung \ref{fig:web_app_screenshot} zeigt einen Screenshot der Web-Applikation.
\begin{figure}[H]
    \centering
    \includegraphics[width=0.5\textwidth]{frontend.png}
    \caption{Screenshot der Web-Applikation}
    \label{fig:web_app_screenshot}
\end{figure}

\section{Diskussion}
Die Auswertung zeigt, dass eine signifikante Anzahl von Artikeln in Schweizer Online-Zeitschriften nach der Publikation geändert wird.
Die Unterscheidung zwischen Tippfehlern und inhaltlichen Änderungen gibt Aufschluss über die Art der vorgenommenen Anpassungen, was bei der Interpretation zu beachten ist.
Rechtschreibfehler weisen auf journalistische Sorgfalt hin, während inhaltliche Änderungen auf neue Informationen oder Korrekturen hindeuten.
Der gesammelte Datensatz bietet die Grundlage für weiterführende Untersuchungen, beispielsweise zur Analyse von inhaltlichen Änderungen bei spezifischen Artikelkategorien.

%-------------------------
% literature
%-------------------------
\onecolumn
\newpage

\bibliography{library}

\newpage

\section{Anhang}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.5\textwidth]{database_er_diagram.png}
    \caption{Datenbank ER Diagram}
    \label{fig:database_er_diagram}
\end{figure}

\end{document}