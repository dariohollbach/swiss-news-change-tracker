% !TEX encoding = UTF-8 Unicode
% !!!  THIS FILE IS UTF-8 !!!
% !!!  MAKE SURE YOUR LaTeX Editor IS CONFIGURED TO USE UTF-8 !!!

% Computational and Data Science Course Paper LaTeX Template
% University of Applied Sciences of the Grisons
% ---------------------------------------------------------------
% Author: Corsin Capol corsin.capol@fhgr.ch
% ---------------------------------------------------------------

%-------------------------
% header
% ------------------------
\documentclass[a4paper,12pt]{scrartcl}
\linespread {1.25}

%-------------------------
% packages and config
% ------------------------
\input{packages_and_configuration}


%-------------------------
% document begin
%-------------------------
\begin{document}

%-------------------------
% title
%-------------------------
\input{title}
\clearpage
\pagestyle{plain} % Setzt den Seitenstil auf normale Seitenzahlen
\setcounter{page}{1} % Setzt den Seitenzähler auf 1


\twocolumn

\section{Einleitung}

Die Präsenz von online Medien wird ständig grösser. 
Gemäss dem Medienbarometer der Schweiz haben die online Medien in der Schweiz im Jahr 2023 eine Meinungsmacht von 27\% \cite{bakomMediengattungen}.
Im Vergleich zu den Printmedien gibt es für online Medien die möglichkeit, Artikel auch nach der Veröffentlichung noch zu ändern.
Wie häufig diese Möglichkeit von unterschiedlichen Schweizer online Zeitschriften genutzt wird, wird in dieser Arbeit untersucht.
Um dies herauszufinden wurden alle Artikel von den Medien in einem regelmässigen Zeitabstand herruntergeladen und in eine Datenbank gespeichert.


\subsection{Eingrenzung}
Die Auswahl der zu untersuchenden online Medien basiert auf deren unterschiedlichen Platzierungen im Medienqualitätsrating (MQR)~\cite{MedienqualitaetsratingMQR24Verein}.
Folgende Medien wurden ausgewählt: 20 Minuten, Watson und SRF News.

\section{Methodik}

Zur Beantwortung der Forschungsfrage wurden mehrere Python-Applikationen entwickelt. 
Der zugehörige Quellcode ist in einem öffentlichen GitHub-Repository\footnote{\url{https://github.com/dariohollbach/swiss-news-change-tracker}} zugänglich.

\begin{figure}[t]
    \centering
    \includegraphics[width=0.5\textwidth]{architecture.drawio.png}
    \caption{Architektur}
    \label{fig:architecture}
\end{figure}

\subsection{Web Scraping}

Der Prozess der Datenextraktion von Webseiten wird als Web-Scraping bezeichnet und gewinnt zunehmend an Bedeutung, da immer mehr Informationen online verfügbar sind~\cite[S. V]{penmanWebScrapingPython2015}.
Für das Web-Scraping wurde eine Python Applikation entwickelt.
Die ausgewählten Medien verfügen alle über einen RSS-Feed.
Um diesen auszulesen wurde das Python Modul \texttt{feedparser} verwendet.
Von dem RSS Feed können die Links zu den Artikeln herausgefunden werden.
Mit dem Python \texttt{request} Modul wurde der Inhalt der Artikel heruntergeladen.
Da die Artikel aus dem Web stammen ist das Format HTML\@. 
Für die Datenbank ist nur der Text eines Artikel von Relevanz.
Dieser Text-Inhalt wurde mithilfe vom Python Modul \texttt{BeautifulSoup} extrahiert.
Beautiful Soup ist ein beliebtes Modul, das eine Webseite parst und eine komfortable Schnittstelle zur Navigation im Inhalt bereitstellt~\cite[S. 26]{penmanWebScrapingPython2015}.

In Python wurde ein Interface für die Crawler der verschiedenen Medien definiert.
Jeder Crawler implementiert dieses Interface und ist für das Herunterladen und Parsen der Artikel eines Mediums zuständig.
Der Hauptteil der Applikation ruft die verschiedenen Crawler auf. 
Dies ist in Abbildung \ref{fig:architecture} dargestellt.

Um die Applikation in einem regelmässigem Intervall auszuführen, wurde ein Cron-Job erstellt. 
Beim erstellen des Cron Jobs sind Probleme aufgetreten, welche schwierig nachzuvollziehen waren. 
Deshalb wurde die Ausgabe der Python Applikation in ein Log-File \texttt{swiss\_news\_change\_tracker\_log} gespeichert.

\subsection{Datenbank}

Für die Speicherung der heruntergeladenen Artikel und deren Änderungen wurde eine SQLite-Datenbank verwendet.
SQLite wurde gewählt, da es eine einfache und leichtgewichtige Lösung ist, welche keine zusätzliche Server-Infrastruktur benötigt.
Die Datenbank besteht aus drei Tabellen: Eine Tabelle für die Zeitschrifen, eine Tabelle für die Artikel und eine Tabelle für die Änderungen.
Das zugehörige Entity-Relationship-Diagramm (ER-Diagramm) der Datenbank ist in Abbildung \ref{fig:database_er_diagram} im Anhang dargestellt.
Wie in Abbildung \ref{fig:architecture} ersichtlich, erfolgt der Zugriff auf die Datenbank durch den Database-Manager mittels SQL-Abfragen.

\subsection{Visualisierung der Änderungen}

Da die reinen Daten der Artikeländerungen mittels SQL-Abfragen nur schwer zu interpretieren sind, wurde eine Web-Applikation zur Visualisierung entwickelt.
Das Frontend wurde mit dem JavaScript-Framework \texttt{Vue.js} umgesetzt.
Für den Datenzugriff wurde eine Flask Server entwickelt, welche dem Frontend die in der Datenbank gespeicherten Artikel und deren Änderungen zur Verfügung stellt.
Diese API greift auf dieselbe Datenbankinfrastruktur zu wie der Web-Scraper. 
Dies ist in Abbildung \ref{fig:architecture} dargestellt.
Die Web-Applikation stellt die Artikel der verschiedenen Medien übersichtlich dar. 
Vorhandene Änderungen eines Artikels können durch eine interaktive Ausklapp-Funktion angezeigt werden, was eine direkte Analyse der Modifikationen ermöglicht.

\subsubsection{Klassifikation der Änderungen}
Eine erste Analyse der erfassten Daten zeigte, dass viele Änderungen lediglich Korrekturen von Rechtschreib- oder Tippfehlern umfassen. Um zwischen solch geringfügigen Anpassungen und substanziellen inhaltlichen Modifikationen zu differenzieren, wurde eine Klassifizierung der Änderungen vorgenommen.
Aufgrund der überschaubaren Anzahl an Änderungen wurde dieser Prozess manuell durchgeführt.
Hierfür wurde die Web-Anwendung so erweitert, dass jede Änderung über ein Dropdown-Menü als Tippfehler oder inhaltliche Anpassung klassifiziert werden kann.

\subsection{Analyse der Daten}
Für die statistische Auswertung der klassifizierten Daten wurde ein Python-Skript unter Verwendung der Bibliothek \texttt{Pandas} und \texttt{matplotlib} entwickelt. 
Dieses ermöglichte es, die Daten zu aggregieren und zu analysieren, um die Forschungsfrage zu beantworten.
Die Relevanz solcher Werkzeuge wird in der Fachliteratur betont: \enquote{Im heutigen datengesteuerten Zeitalter stehen Organisationen [...] vor der Herausforderung, aus den riesigen Datenmengen [...] aussagekräftige Informationen zu gewinnen. [...] Genau hier kommt Pandas ins Spiel.}~\cite[S. 1]{firdoseUltimatePandasData2024}.


\section{Resultate}

In der Zeit vom 10. November 2025 bis zum 20. November 2025 wurden insgesammt 1767 Artikel von den drei ausgewählten Medien heruntergeladen.
Davon wurden 381 Artikel mindestens einmal geändert.

\begin{table*}[b]
    \centering
    \caption{Zusammenfassung der Artikel und Änderungen pro Medium}
    \label{tab:change_summary}
    \begin{tabular}{lrrrr}
        \hline
        \textbf{Zeitung} & \textbf{Total Artikel} & \textbf{Total Änderungen} & \textbf{Tippfehler} & \textbf{Inhaltliche Änd.} \\
        \hline
        20 Minuten & 624 & 148 & 88 & 60 \\
        Watson & 601 & 96 & 51 & 45 \\
        SRF News & 542 & 137 & 78 & 59 \\
        \hline
        \textbf{Total} & \textbf{1767} & \textbf{381} & \textbf{217} & \textbf{164} \\
        \hline
    \end{tabular}
\end{table*}

Tabelle \ref{tab:change_summary} fasst die gesammelten Daten zusammen. 
Obwohl die manuelle Klassifikation eine gewisse Ungenauigkeit durch subjektive Einschätzungen mit sich bringt, bietet sie dennoch einen guten Überblick über die Art der vorgenommenen Änderungen.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.5\textwidth]{article_and_change_counts_by_newspaper.png}
    \caption{Anzahl \"{A}nderungen pro Medium}
    \label{fig:article_and_change_counts_by_newspaper}
\end{figure}
Abbildung \ref{fig:article_and_change_counts_by_newspaper} zeigt die Anzahl Änderungen pro Medium.
Es ist ersichlich, dass im Durchschnitt ungefähr jeder fünfte Artikel geändert wurde.
20 Minuten und SRF News weisen dabei eine ähnliche Änderungsrate auf, während Watson etwas weniger Änderungen aufweist.
Dabei ist bei der Interpretation zu beachten, dass bei vielen Artikeln auch nur die positionierung von Inhalten geändert wurde, ohne dass der eigentliche Inhalt angepasst wurde.
Dies wurde ebenfalls als Tippfehler klassifiziert.


Zum Resultat der Arbeit gehört auch die Web-Applikation zur Visualisierung der Artikeländerungen.
Denn die Analyse der reinen Zahlen gibt keinen Einblick in die Art der Änderungen.
Abbildung \ref{fig:web_app_screenshot} zeigt einen Screenshot der Web-Applikation.
\begin{figure}[H]
    \centering
    \includegraphics[width=0.5\textwidth]{frontend.png}
    \caption{Screenshot der Web-Applikation}
    \label{fig:web_app_screenshot}
\end{figure}

\section{Diskussion}
Die durchgeführte Analyse zeigt, dass eine beträchtliche Anzahl von Artikeln in Schweizer online Medien nach ihrer Veröffentlichung geändert wird.
Die Unterscheidung zwischen Tippfehlern und inhaltlichen Änderungen ist dabei besonders relevant, da sie Aufschluss über die Art der vorgenommenen Anpassungen gibt.
Während Tippfehlerkorrekturen oft auf redaktionelle Sorgfalt hinweisen, deuten inhaltliche Änderungen auf eine Reaktion auf neue Informationen oder Leserfeedback hin.
Der Gesammelte Datensatz bietet zudem die Grundlage für weiterführende Untersuchungen, beispielsweise zur zeitlichen Verteilung von Änderungen oder zur Analyse spezifischer Themenbereiche, die häufiger angepasst werden.

%-------------------------
% literature
%-------------------------
\onecolumn
\newpage

\bibliography{library}

\newpage

\section{Anhang}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.5\textwidth]{database_er_diagram.png}
    \caption{Datenbank ER Diagram}
    \label{fig:database_er_diagram}
\end{figure}

\end{document}